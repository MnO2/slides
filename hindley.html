<!DOCTYPE html>
<html>
  <head>
    <title>Title</title>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
    <style type="text/css">
      @import url(https://fonts.googleapis.com/css?family=Yanone+Kaffeesatz);
      @import url(https://fonts.googleapis.com/css?family=Droid+Serif:400,700,400italic);
      @import url(https://fonts.googleapis.com/css?family=Ubuntu+Mono:400,700,400italic);

      body { font-family: 'Droid Serif'; }
      h1, h2, h3 {
        font-family: 'Yanone Kaffeesatz';
        font-weight: normal;
      }
      .remark-code, .remark-inline-code { font-family: 'Ubuntu Mono'; }

      .red    { color: #FF4943; }
      .gray   { color: #787878; }
      .green  { color: #87A558; }
      .blue   { color: #41C8F0; }
      .yellow { color: #DBEC62; }
      .large p { font-size: 4em; }

      .large-picture img { width: 400px; }
      .medium-picture img { width: 300px; }
      .small-picture img { width: 200px; }
      .tiny-picture img { width: 100px; }
    </style>
  </head>
  <body>
    <textarea id="source">

class: center, middle

# Hindley Milner Type System


### Paul Meng
### Twitch, June 3rd, 2015.

---

## ![h-and-m](image/HM.png) T-shirt

.large-picture[![what-part](image/what_part_of_types_dont_you_understand.jpg)]
--

.small-picture[![wtf](image/jackie-chan-wtf.png)]


---


## Hindley Milner Type Rules

.large-picture[![syntax-directed-hm](image/syntax_directed_hm.jpg)]

* It's quite daunting at first glance, and you just can't understand any single bit of it if you are not from academic background.

---

## Why is it so hard ?

* .red[The language (predicate logic) used to describe the system is the language used in academy. The purpose is to be exact but not for comprehension.]
* Academic people just use lots of jargon in communication for brevity. As a newcomer you have to pickup the intuition and jargon.
* Sometimes the form you see is not the form where you could read out an algorithm. (Not syntax-directed form)
* You don't understand why it has to be in a simplified formal language when it comes to a tutorial. What it has to do with Haskell? Can I just learn the model for the real world Haskell?
  - Haskell's type system is much more complicated. but as a ML family member, it is possible to extend the simplified formal language to the complexity of Haskell
* It's unclear why we need Hindley Milner type system? What's the motivation for the researcher developed such kind of system. We just accepted it as a part of the programming language?
  - It is based on solid researches on lambda calculus, and it inspired lots of extensions and new models ever since. Although with its defect, it is good to learn that to get the idea of similar models in the family.


---

## Why is it so hard ?

* The language (predicate logic) used to describe the system is the language used in academy. The purpose is to be exact but not for comprehension.
* .red[Academic people just use lots of jargon in communication for brevity. As a newcomer you have to pickup the intuition and jargon.]
* Sometimes the form you see is not the form where you could read out an algorithm. (Not syntax-directed form)
* You don't understand why it has to be in a simplified formal language when it comes to a tutorial. What it has to do with Haskell? Can I just learn the model for the real world Haskell?
  - Haskell's type system is much more complicated. but as a ML family member, it is possible to extend the simplified formal language to the complexity of Haskell
* It's unclear why we need Hindley Milner type system? What's the motivation for the researcher developed such kind of system. We just accepted it as a part of the programming language?
  - It is based on solid researches on lambda calculus, and it inspired lots of extensions and new models ever since. Although with its defect, it is good to learn that to get the idea of similar models in the family.


---

## Why is it so hard ?

* The language (predicate logic) used to describe the system is the language used in academy. The purpose is to be exact but not for comprehension.
* Academic people just use lots of jargon in communication for brevity. As a newcomer you have to pickup the intuition and jargon.
* .red[Sometimes the form you see is not the form where you could read out an algorithm. (Not syntax-directed form)]
* You don't understand why it has to be in a simplified formal language when it comes to a tutorial. What it has to do with Haskell? Can I just learn the model for the real world Haskell?
  - Haskell's type system is much more complicated. but as a ML family member, it is possible to extend the simplified formal language to the complexity of Haskell
* It's unclear why we need Hindley Milner type system? What's the motivation for the researcher developed such kind of system. We just accepted it as a part of the programming language?
  - It is based on solid researches on lambda calculus, and it inspired lots of extensions and new models ever since. Although with its defect, it is good to learn that to get the idea of similar models in the family.

---

## Why is it so hard ?

* The language (predicate logic) used to describe the system is the language used in academy. The purpose is to be exact but not for comprehension.
* Academic people just use lots of jargon in communication for brevity. As a newcomer you have to pickup the intuition and jargon.
* Sometimes the form you see is not the form where you could read out an algorithm. (Not syntax-directed form)
* .red[You don't understand why it has to be in a simplified formal language when it comes to a tutorial. What it has to do with Haskell? Can I just learn the model for the real world Haskell?]
  - Haskell's type system is much more complicated. but as a ML family member, it is possible to extend the simplified formal language to the complexity of Haskell
* It's unclear why we need Hindley Milner type system? What's the motivation for the researcher developed such kind of system. We just accepted it as a part of the programming language?
  - It is based on solid researches on lambda calculus, and it inspired lots of extensions and new models ever since. Although with its defect, it is good to learn that to get the idea of similar models in the family.

---

## Why is it so hard ?

* The language (predicate logic) used to describe the system is the language used in academy. The purpose is to be exact but not for comprehension.
* Academic people just use lots of jargon in communication for brevity. As a newcomer you have to pickup the intuition and jargon.
* Sometimes the form you see is not the form where you could read out an algorithm. (Not syntax-directed form)
* You don't understand why it has to be in a simplified formal language when it comes to a tutorial. What it has to do with Haskell? Can I just learn the model for the real world Haskell?
  - .red[Haskell's type system is much more complicated. but as a ML family member, it is possible to extend the simplified formal language to the complexity of Haskell]
* It's unclear why we need Hindley Milner type system? What's the motivation for the researcher developed such kind of system. We just accepted it as a part of the programming language?
  - It is based on solid researches on lambda calculus, and it inspired lots of extensions and new models ever since. Although with its defect, it is good to learn that to get the idea of similar models in the family.

---

## Why is it so hard ?

* The language (predicate logic) used to describe the system is the language used in academy. The purpose is to be exact but not for comprehension.
* Academic people just use lots of jargon in communication for brevity. As a newcomer you have to pickup the intuition and jargon.
* Sometimes the form you see is not the form where you could read out an algorithm. (Not syntax-directed form)
* You don't understand why it has to be in a simplified formal language when it comes to a tutorial. What it has to do with Haskell? Can I just learn the model for the real world Haskell?
  - Haskell's type system is much more complicated. but as a ML family member, it is possible to extend the simplified formal language to the complexity of Haskell
* .red[It's unclear why we need Hindley Milner type system? What's the motivation for the researcher developed such kind of system. We just accepted it as a part of the programming language?]
  - It is based on solid researches on lambda calculus, and it inspired lots of extensions and new models ever since. Although with its defect, it is good to learn that to get the idea of similar models in the family.

---

## Why is it so hard ?

* The language (predicate logic) used to describe the system is the language used in academy. The purpose is to be exact but not for comprehension.
* Academic people just use lots of jargon in communication for brevity. As a newcomer you have to pickup the intuition and jargon.
* Sometimes the form you see is not the form where you could read out an algorithm. (Not syntax-directed form)
* You don't understand why it has to be in a simplified formal language when it comes to a tutorial. What it has to do with Haskell? Can I just learn the model for the real world Haskell?
  - Haskell's type system is much more complicated. but as a ML family member, it is possible to extend the simplified formal language to the complexity of Haskell
* It's unclear why we need Hindley Milner type system? What's the motivation for the researcher developed such kind of system. We just accepted it as a part of the programming language?
  - .red[It is based on solid researches on lambda calculus, and it inspired lots of extensions and new models ever since. Although with its defect, it is good to learn that to get the idea of similar models in the family.]

---

## Using predicate logic as lightly as possible

* .red[This talk tries to derive it from intuition and examples.]
* Trade off exactnesss for easier comprehension.
* We would define the simplified one and gradually move to the harder ones.

---

## Using predicate logic as lightly as possible

* This talk tries to derive it from intuition and examples.
* .red[Trade off exactnesss for easier comprehension.]
* We would define the simplified one and gradually move to the harder ones.


---

## Using predicate logic as lightly as possible

* This talk tries to derive it from intuition and examples.
* Trade off exactnesss for easier comprehension.
* .red[We would define the simplified one and gradually move to the harder ones.]

---

## Starting off with an observation

* In McDonald, a simple burger is consist of breads and beef.

.tiny-picture[![](image/big-mac-bread.jpg)]
.tiny-picture[![](image/big-mac-beef.jpg)]

* How could we express that we would like to "make" a burger?

---

## Starting off with an observation

* We could express it in a simplified formal language.

``` haskell
data Term = Var Name              -- x
          | Lit Int               -- 3
          | App Term Term         -- f x
          | Lam Name Term         -- \x -> x
```

--
* I would really love to call this language as .blue["System Mc"], but that is actually a misnomer. Its name is .blue[lambda calculus].
* Then "make" could be expressed as

--

![](image/burger_lambda.jpg)

``` haskell
(\x -> \y -> burger) bread beef
```

--
* Is unsafe. You could put anything into the x, y and makes it a burger. (Cockroach?)

---

## Simply typed lambda calculus

* Therefore we extend this language, to add type annotation: .blue[x :: Burger] 

``` haskell
data Term = Var Name              -- x
          | Lit Int               -- 3
          | App Term Term         -- f x
          | Lam Name Term         -- \x -> x
          | Ann Term Rho          -- (f x) :: Burger
```
* Given a built-in rule (We, the programmer as the oracle, declare this as the Hamburger Making theorem.)

$$
make :: Bread \rightarrow Beef \rightarrow Burger
$$

* Then we could check if this program follows the rule of the theorem.

``` haskell
((\x: Bread -> \y: Beef -> burger) :: Bread -> Beef -> Burger) bread) beef
```


---

## It's not only for type checking.

* Because the rule is not ambiguous, we could run the rule checking "backward" to learn the type of a term, with all the constant's type known.
* With human brains, we could see the answer by the rules in a glance, but how to derive an algorithm?

* Rule:
$$
make :: Bread \rightarrow Beef \rightarrow Burger
$$

* Missing y type

``` haskell
((\x: Bread -> \y: ??? -> burger) :: Bread -> Beef -> Burger) bread) beef
```

---

## Let's get started from fuzzy idea

* We would like to have a `typecheck` function, when given a value level `Term` expression, return an inferred `Rho` type. And since the inference involves some states, we have to put it in a Monad `Tc`.
* `typecheck` calls `inferRho` to states its implementation.

``` haskell
typecheck :: Term -> Tc Rho
typecheck e = inferRho e
```

--

* We allocate a "type variable", and leave the `tcRho` to fill out the type variable and read it afterward. We also put it in another type to mark that we are doing "inference".

``` haskell
inferRho :: Term -> Tc Rho
inferRho expr
  = do { ref <- newTcRef (error "inferRho: empty result")
       ; tcRho expr (Infer ref)
       ; readTcRef ref }
```
* Then what's next and our goal?

---

## Target: Reformulate our problem


* Notice that we could write down some equations when seeing the formula. Then we could solve the eqautions like high-school algebra.

``` haskell
((\x: Bread -> \y: ??? -> burger) :: Bread -> Beef -> Burger) bread) beef
```

``` haskell
a -> b -> c = Bread -> Beef -> Burger
a = Bread
c = Burger
```

* Is this observation correct? 

--

* .blue[Yes.] The essense of type inference is walking the abstract syntax tree and collect constraints we must satisfy. Therefore we would reformulate the problem to so-called "unification problem".

---

## Target: Reformulate our problem

* Unification problem example

$$
T_1 \rightarrow T_1 * bool = (T_3 + int) \rightarrow T_2
$$

--

* Then we have a solution 

$$ \\{ T_1 \Rightarrow T_3 + int, \, T_2 \Rightarrow (T_3 + int) * bool \\} $$

--

* Our target is to walk the tree and collect Constraints

``` haskell
a -> b -> c = Bread -> Beef -> Burger
a = Bread
c = Burger
```

* Then solving the equations gives us `b = Beef`

--

* We call this substitution "unifier" in academic terminology.


---

## Formulation: Type variable expansion

* But notice that we don't have "type variable" either in the syntax or parsed abstract syntax tree.

``` haskell
((\x: Bread -> \y: ??? -> burger) :: Bread -> Beef -> Burger) bread) beef
```

--

* We have to figure out a way to generate the "type variables". In more complicated cases it also comes with arrow (->), and it makes up a "type expression".

--

* Grammar for type variable expansion in type inference.

$$
\rho ::= \tau \\\
\tau ::= \tau \rightarrow \tau \, \vert \, ContantType \\\
$$

* With this grammar, we have the "meta type variable" for expanding type expressions.
* That is the `Rho` we mentioned.

``` haskell
inferRho :: Term -> Tc Rho
```

---
## Formulation: Type variable expansion

$$
\rho ::= \tau \\\
\tau ::= \tau \rightarrow \tau \, \vert \, ContantType \\\
$$

* And now we have the "type expression" defined.

``` haskell
type Rho   = Type
type Tau   = Type

data Type = Fun    Type Type ›    -- Function type
    ›     | TyCon  TyCon      ›   -- Type constants
    ›     | TyVar  TyVar      ›   -- Type variable with name
    ›     | MetaTv MetaTv     ›   -- A meta type variable

data TyVar
  = SkolemTv String Uniq›   -- Like the "a1", "a2", "a3" you see in GHC compiler message
```

--
* Then we could start walking the AST of the expression

``` haskell
((\x: Bread -> \y: ??? -> burger) :: Bread -> Beef -> Burger) bread) beef
```

---

## Tree Walking

``` haskell
inferRho expr
  = do { ref <- newTcRef (error "inferRho: empty result")
       ; tcRho expr (Infer ref)
       ; readTcRef ref }
```

.medium-picture[![slc-ex5](image/SLC_ex1.svg)]

---

## Tree Walking

``` haskell
tcRho (App fun arg) exp_ty
  = do { fun_ty <- inferRho fun
       ; (arg_ty, res_ty) <- unifyFun fun_ty
       ; ....
       }
```

.medium-picture[![slc-ex6](image/SLC_ex2.svg)]

* Wait.. What is `unifyFun` ?

---

## Robinson's Unification Algorithm in Action

* Comparing to collecting constraints and solving them afterward, solving while walking is easier for explanation.
* This function does two things: type expression expansion and unification.
* `unify` the symbol `tau` with the formula of `a1 -> a2`
* That is, Contraint $\tau = a1 \rightarrow a2$
* We allocate type variables with `newTyVarTy`

``` haskell
unifyFun :: Rho -> Tc (Rho, Rho)
unifyFun (Fun arg res) = return (arg,res)
unifyFun tau           = do { arg_ty <- newTyVarTy
                            ; res_ty <- newTyVarTy
                            ; unify tau (arg_ty --> res_ty)
                            ; return (arg_ty, res_ty) }
```

---

## Robinson's Unification Algorithm in Action

* If the argument is `Fun`, then first `unify` the argument, then `unify` its body.

``` haskell
unify :: Tau -> Tau -> Tc ()
unify (Fun arg1 res1) (Fun arg2 res2)
  = do { unify arg1 arg2
       ; unify res1 res2 }
```

$$
unify(a \rightarrow b = Burger \rightarrow Burger) = \\\ 
unify(a = Burger) \cup unify(b = Burger)
$$

--

* If the type is `badType`, then indicate it is a compilation error.

``` haskell
unify ty1 ty2
  | badType ty1 || badType ty2  -- Compiler error
  = failTc (text "Panic! Unexpected types in unification:" <+>
            vcat [ppr ty1, ppr ty2])
```

---

## Robinson's Unification Algorithm in Action

* If one of them is meta type variable `Rho` or `Tau`

``` haskell
unify (MetaTv tv1) (MetaTv tv2) | tv1 == tv2 = return ()
unify (MetaTv tv) ty = unifyVar tv ty
unify ty (MetaTv tv) = unifyVar tv ty
```

``` haskell
unifyVar :: MetaTv -> Tau -> Tc ()
unifyVar tv1 ty2
  = do { mb_ty1 <- readTv tv1
       ; case mb_ty1 of
           Just ty1 -> unify ty1 ty2
           Nothing  -> error "in simply type calculus, type shouldn't be unbound" }
```

---

## Robinson's Unification Algorithm in Action

* If it is a constant type, then check if they are matched.

``` haskell
unify (TyCon tc1) (TyCon tc2) | tc1 == tc2 
    = return ()
```

$$
unify(Burger = Burger) = \Phi \\\
$$

--

* If they are type variables, check if their "names" are the same. That is "a1 = a1". "a1" and "a2" are not equal. It is confusing but you would see it when we add the generalization part.
``` haskell
unify (TyVar tv1)  (TyVar tv2)  | tv1 == tv2 
    = return ()
```
--

* Otherwise, failed to check the program.

``` haskell
unify ty1 ty2 = failTc (text "Cannot unify types:" <+> vcat [ppr ty1, ppr ty2])
```

--

* With unification algorithm, we could get back to the tree walking.

---

.medium-picture[![slc-ex3](image/SLC_ex2.svg)]

* `checkRho` do the typechecking for the argument
* `instRho` writes the type back to the reference
* We have this extra layer of abstraction is for the later extesion.

``` haskell
tcRho (App fun arg) exp_ty = do { fun_ty <- inferRho fun
                                ; (arg_ty, res_ty) <- unifyFun fun_ty
                                ; checkRho arg arg_ty
                                ; instRho res_ty exp_ty }

checkRho :: Term -> Rho -> Tc ()
checkRho expr ty = tcRho expr (Check ty)

```


---

.medium-picture[![slc-ex3](image/SLC_ex2.svg)]

* `checkRho` do the typechecking for the argument
* `instRho` writes the type back to the reference
* We have this extra layer of abstraction is for the later extesion.

``` haskell
tcRho (App fun arg) exp_ty = do { fun_ty <- inferRho fun
                                ; (arg_ty, res_ty) <- unifyFun fun_ty
                                ; checkRho arg arg_ty
                                ; instRho res_ty exp_ty }

instRho :: Rho -> Expected Rho -> Tc ()
instRho t1 (Check t2) = unify t1 t1
instRho t1 (Infer r) = writeTcRef r t1
```


---
.medium-picture[![slc-ex3](image/SLC_ex3.svg)]

``` haskell
tcRho (App fun arg) exp_ty = do { fun_ty <- inferRho fun
                                ; (arg_ty, res_ty) <- unifyFun fun_ty
                                ; checkRho arg arg_ty
                                ; instRho res_ty exp_ty }

checkRho :: Term -> Rho -> Tc ()
checkRho expr ty = tcRho expr (Check ty)

instRho :: Rho -> Expected Rho -> Tc ()
instRho t1 (Check t2) = unify t1 t1
instRho t1 (Infer r) = writeTcRef r t1
```

---

.medium-picture[![slc-ex4](image/SLC_ex4.svg)]

``` haskell
tcRho (Lam var body) (Infer ref)
  = do { var_ty  <- newTyVarTy
       ; body_ty <- extendVarEnv var var_ty (inferRho body)
       ; writeTcRef ref (var_ty --> body_ty) }
tcRho (Lam var body) (Check exp_ty)
  = do { (var_ty, body_ty) <- unifyFun exp_ty
       ; extendVarEnv var var_ty (checkRho body body_ty) }
```

* We allocate a type variable for lambda argument, then using `extendVarEnv` to put a record marking the argument's type is `var_ty`. This term could be lookedup during the inference of `body`.

---

.medium-picture[![slc-ex4](image/SLC_ex4.svg)]

``` haskell
tcRho (Lam var body) (Infer ref)
  = do { var_ty  <- newTyVarTy
       ; body_ty <- extendVarEnv var var_ty (inferRho body)
       ; writeTcRef ref (var_ty --> body_ty) }
tcRho (Lam var body) (Check exp_ty)
  = do { (var_ty, body_ty) <- unifyFun exp_ty
       ; extendVarEnv var var_ty (checkRho body body_ty) }
```

* With the environment extended, we inference `body`, and put the inferred type `var_ty --> body_ty` into reference.
* If we are doing type checking, we just do the unification. For the separation of cases, it is also for the later extension.

---

.medium-picture[![slc-ex6](image/SLC_ex5.svg)]

``` haskell
tcRho (Var v) exp_ty•
  = do { v_rho <- lookupVar v•
       ; instRho v_rho exp_ty }
```

* lookup the term `v` in the environment, and save it into `exp_ty`

---

.medium-picture[![slc-ex6](image/SLC_ex6.svg)]

``` haskell
tcRho (Lam var body) (Infer ref)
  = do { var_ty  <- newTyVarTy
       ; body_ty <- extendVarEnv var var_ty (inferRho body)
       ; writeTcRef ref (var_ty --> body_ty) }
tcRho (Lam var body) (Check exp_ty)
  = do { (var_ty, body_ty) <- unifyFun exp_ty
       ; extendVarEnv var var_ty (checkRho body body_ty) }
```

---

.medium-picture[![slc-ex6](image/SLC_ex7.svg)]

``` haskell
tcRho (Var v) exp_ty
  = do { v_rho <- lookupVar v
       ; instRho v_rho exp_ty }
```

* lookup the term `v` in the environment, and save it into `exp_ty`

---

.medium-picture[![slc-ex6](image/SLC_ex8.svg)]

``` haskell
tcRho (Lit _) exp_ty
  = instRho BurgerType exp_ty
```

* Constant type is trivial.

---

.medium-picture[![slc-ex6](image/SLC_ex9.svg)]

``` haskell
tcRho (lit _) exp_ty
  = instRho BurgerType exp_ty
```

* constant type is trivial.

---

.medium-picture[![slc-ex6](image/SLC_ex10.svg)]

``` haskell
tcRho (lit _) exp_ty
  = instRho BurgerType exp_ty
```

* constant type is trivial.


---

.medium-picture[![slc-ex3](image/SLC_ex2.svg)]

``` haskell
tcRho (App fun arg) exp_ty = do { fun_ty <- inferRho fun
                                ; (arg_ty, res_ty) <- unifyFun fun_ty
                                ; checkRho arg arg_ty
                                ; instRho res_ty exp_ty }
```

* `arg_ty` is `Beef`
* `res_ty` is `Burger`
* save `Burger` into `exp_ty`

``` haskell
inferRho expr
  = do { ref <- newTcRef (error "inferRho: empty result")
       ; tcRho expr (Infer ref)
       ; readTcRef ref }
```

---

## Tree Walking

* Finally we get the whole program's type

``` haskell
typecheck :: Term -> Tc Rho
typecheck e = inferRho e
```

--
* However, this type system is too simple. No generalization.

---

## The defect of simply typed lambda calculus

* Suppose that we would like to have a generalized version of hamburger making.
* Hamburger is not only for meat, but could be prawn. And we could use Rice for Bread

![](image/jarkarta_burger.jpg)


``` haskell
(\f -> ((f bread meat), (f bread prawn), (f rice meat)) ) (make)
```


---

## The defect of simply typed lambda calculus

* The trick discovered by Hindley and Milner independently is to add a "let" into grammar
* It's called Let polymorphism.

``` haskell
let f = make in ((f bread meat), (f bread prawn), (f rice meat))
```

* The type system is also generalized. For the language to describe "type" (type expression) is added with polytype, that is `forall a. a`

``` haskell
forall a b. a -> b -> Burger
```


---

## Let Polymorphism

* Let's modify the grammar for value level expression.

``` haskell
data Term = Var Name              -- x
          | Lit Int               -- 3
          | App Term Term         -- f x
          | Lam Name Term         -- \ x -> x
          | Let Name Term Term    -- let x = f y in x+1
          | Ann Term Sigma        -- (f x) :: Int
```

* We add a "Let Name Term Term" here
* Polytypes (We use Sigma here) are types containing variables bound by one or more for-all quantifiers

$$
\forall a. a \rightarrow a \rightarrow a
$$

* Then we extend the structure we previously defined one by one.

---

## Let Polymorphism

* Then we extends the type expression.

$$ 
\sigma ::= \forall a. \rho \\\
\rho ::= \tau \\\
\tau ::= \tau \rightarrow \tau \, | \, ConstantType \\\
$$

* We add another meta variable "Sigma" for type level expansion.
* And "BoundTv" to capture the "forall" polytype.

``` haskell
type Sigma = Type
type Rho   = Type›  -- No top-level ForAll
type Tau   = Type›  -- No ForAlls anywhere

data Type = ForAll [TyVar] Rho›   -- Forall type
    ›     | Fun    Type Type ›    -- Function type
    ›     | TyCon  TyCon      ›   -- Type constants
    ›     | TyVar  TyVar      ›   -- Always bound by a ForAll
    ›     | MetaTv MetaTv     ›   -- A meta type variable

data TyVar
  = BoundTv String› ›       -- A type variable bound by a ForAll
  | SkolemTv String Uniq›   -- A skolem constant; the String is•
```


---

## Instantiation

* With the polytype introduced, a corresponding concept is introduced, it's called instantiation.

--

* It's replacing "type variable" identified by "schema" with a fresh "type variable" or "type constant"

--

* The LHS could be rewritten as the RHS

$$
\forall a. a \leq Int \\\
\forall a. a \rightarrow a \leq Int \rightarrow Int \\\
\forall a. a \rightarrow a \leq b \rightarrow b \\\
\forall a. a \rightarrow a \leq c \rightarrow c \\\
$$


---

## Instantiation

* Substitute the type variable appears in the topmost `forall`, with newly instantiated type variables, they are not the same from any other type variables.

``` haskell
instantiate :: Sigma -> Tc Rho
instantiate (ForAll tvs ty) = do { tvs' <- mapM (\_ -> newMetaTyVar) tvs
                                 ; return (substTy tvs (map MetaTv tvs') ty) }
instantiate ty = return ty
```

* We split `instSigma` in two cases is for later higher-rank extension.

``` haskell
instRho :: Rho -> Expected Rho -> Tc ()
instRho t1 (Check t2) = unify t1 t1
instRho t1 (Infer r) = writeTcRef r t1
```

Becomes

``` haskell
instSigma :: Sigma -> Expected Rho -> Tc ()
instSigma t1 (Check t2) = unify t1 t2
instSigma t1 (Infer r)  = do { t1' <- instantiate t1
                             ; writeTcRef r t1' }
```


---

## Generalization

* Another concept introduced is called "generalization".
* It's replacing a "type variable" with a "polytype". Think it like replacing a simple function in C++ and generalize it with a C++ template function.

``` haskell
inferRho expr
  = do { ref <- newTcRef (error "inferRho: empty result")
       ; tcRho expr (Infer ref)
       ; readTcRef ref }
```

Becomes

``` haskell
inferSigma :: Term -> Tc Sigma
inferSigma e
   = do { exp_ty <- inferRho e
        ; env_tys <- getEnvTypes
        ; env_tvs <- getMetaTyVars env_tys
        ; res_tvs <- getMetaTyVars [exp_ty]
        ; let forall_tvs = res_tvs \\ env_tvs
        ; quantify forall_tvs exp_ty }
```

* First using `inferRho` to infer the type of the term, getting `exp_ty`, in `exp_ty` it contains some unbound type variables.
* We use `quantify` to add `forall` for those unbound type variables.

---

## Generalization

``` haskell
checkRho :: Term -> Rho -> Tc ()
checkRho expr ty = tcRho expr (Check ty)
```

Becomes

``` haskell
checkSigma :: Term -> Sigma -> Tc ()
checkSigma expr sigma
= do { (skol_tvs, rho) <- skolemise sigma
     ; checkRho expr rho
     ; env_tys <- getEnvTypes
     ; esc_tvs <- getFreeTyVars (sigma : env_tys)
     ; let bad_tvs = filter (`elem` esc_tvs) skol_tvs
     ; check (null bad_tvs)
             (text "Type not polymorphic enough") }
```


---

.medium-picture[![slc-ex6](image/let_ex1.svg)]

``` haskell
let f = \x -> \y -> burger in ((f bread) meat)
```

---

.medium-picture[![slc-ex6](image/let_ex2.svg)]

* When bumping into a `Let`, we use `inferSigma` but not `inferRho`. `inferSigma` will generalize the type expression with a toplevel `forall` in `var_ty`. So that the `forall` variables could be freely instantiated duing the inference of the `body`.

``` haskell
tcRho (Let var rhs body) exp_ty
  = do { var_ty <- inferSigma rhs
       ; extendVarEnv var var_ty (tcRho body exp_ty) }
```

---

.medium-picture[![slc-ex6](image/let_ex13.svg)]

* When bumping into a `App`, we no longer use `checkRho` or `instRho`. The polytype version `checkSigma` and `instSigma` would typecheck the argument see if the function argument type could subsume the input argument type. And `instSigma` would instantiate the function return type to the expected type of `App`

``` haskell
tcRho (App fun arg) exp_ty
  = do { fun_ty <- inferRho fun
       ; (arg_ty, res_ty) <- unifyFun fun_ty
       ; checkSigma arg arg_ty
       ; instSigma res_ty exp_ty }
```

---

.medium-picture[![slc-ex6](image/let_ex13.svg)]

* For contant case, it is also no longer a simple saving, but has to instantiate the constant type.

``` haskell
tcRho (Lit _) exp_ty
  = instSigma intType exp_ty
```

---

.medium-picture[![slc-ex6](image/let_ex13.svg)]

* for `Var` case, the instantiation also has to be applied.

``` haskell
tcRho (Var v) exp_ty
  = do { v_sigma <- lookupVar v
       ; instSigma v_sigma exp_ty }
```

* For annotation, we would check if the marked annotation could subsume the type of the `body`, if it does, then using annotation type to instantiate expected type.

``` haskell
tcRho (Ann body ann_ty) exp_ty
   = do { checkSigma body ann_ty
        ; instSigma ann_ty exp_ty }
```


---

## Change in Unification

* For `unifyVar`, now it is possible to be unbound. We add `unifyUnboundVar` to handle this case.

``` haskell
unifyVar :: MetaTv -> Tau -> Tc ()
unifyVar tv1 ty2
  = do { mb_ty1 <- readTv tv1
       ; case mb_ty1 of
           Just ty1 -> unify ty1 ty2
           Nothing  -> unifyUnboundVar ty1 ty2 }
```

``` haskell
unifyUnboundVar :: MetaTv -> Tau -> Tc ()
unifyUnboundVar tv1 ty2@(MetaTv tv2)
  = do { mb_ty2 <- readTv tv2
       ; case mb_ty2 of
           Just ty2' -> unify (MetaTv tv1) ty2'
           Nothing  -> writeTv tv1 ty2 }

unifyUnboundVar tv1 ty2
  = do { tvs2 <- getMetaTyVars [ty2]
       ; if tv1 `elem` tvs2 then
            occursCheckErr tv1 ty2
         else
            writeTv tv1 ty2 }
```


---

## What's the defect of hindley-milner type system?

* Even with the addition of "let", it only tells the system to "generalize" at the syntax where "let" happened.

```haskell
(\f -> (f "foo", f 13)) (\x -> x)
```

* Consider the following use case. We want to have the `make` be passed in `makeBurgers` function

```haskell
make :: forall a b. a -> b -> Burger

makeBurgers :: (forall a b. a -> b -> Burger) -> (Burger, Burger)
makeBurgers g = let f x = (x bread beef, x bread prawn)
                 in f g

makeBurgers make
```

* It would not typecheck of hindley-milner, since the `makeBurgers`'s forall is not at the top level.

---

## Higher-rank type system 

* To solve the problem of let polymorphism where it is not generalized at the "argument"

* We add a type annotation to help the type system to generalize at the argument, without a big change in hindley-milner type system.


---

## Change in Value and Type Expression

* Add type annotation in the abstraction rule, i.e. ALam

``` haskell
data Term = Var Name              -- x
          | Lit Int               -- 3
          | App Term Term         -- f x
          | Lam Name Term         -- \ x -> x
          | ALam Name Sigma Term  -- \ x -> x
          | Let Name Term Term    -- let x = f y in x+1
          | Ann Term Sigma        -- (f x) :: Int
```

* Make $\rho$ could derive $\sigma \rightarrow \sigma$

$$
\sigma ::= \forall a. \rho \\\
\rho ::= \tau \, | \, \sigma \rightarrow \sigma^{\prime} \\\
\tau::= \tau \rightarrow \tau \, | \, ConstantType \\\
$$


---

## Change in Inference

* For inference, it is not intuitive. Extend the environment by marking `var` with `var_ty`, and do the inference for `body`
* For type checking, a special case we have to deal with, that is determining if a type expression covers another type expression. In academic terminology, it is called "subsumption".
* Denoted by `subsCheck`

``` haskell
tcRho (ALam var var_ty body) (Check exp_ty)
  = do { (arg_ty, body_ty) <- unifyFun exp_ty
       ; subsCheck arg_ty var_ty
       ; extendVarEnv var var_ty (checkRho body body_ty) }

tcRho (ALam var var_ty body) (Infer ref)
  = do { body_ty <- extendVarEnv var var_ty (inferRho body)
       ; writeTcRef ref (var_ty --> body_ty) }
```


---

## Subsumption

* Determine if a poly type expression could actually be incorporated into another poly type expression.

* Are these two types equivalent?

$$
\forall a. a \rightarrow (\forall b.b \rightarrow b) \\\
\forall ab. a \rightarrow b \rightarrow b \\\
$$

* They should be isomorphic. The hindley milner could only infer the type with forall at the top level, just looks like the second one. But what we would like to mark the type like the first one. How to get these two be equivalent by extending the existing rules?


* That is, using tricks to make one polytype being "subsumed" by another polytype.

$$
\forall a. a \rightarrow (\forall b.b \rightarrow b) \leq \forall ab. a \rightarrow b \rightarrow b \\\
\forall a. a \rightarrow (\forall b.b \rightarrow b) \geq \forall ab. a \rightarrow b \rightarrow b \\\
$$


---

## Subsumption

* We define the prenex form: With all of the "forall" at the "head" of the type annotation.

--

* And the prenex conversion is like the following, floating the "forall" at the right of the arrows to the top.

$$
\forall a. a \rightarrow (\forall b.b \rightarrow b)
$$

to 

$$
\forall ab. a \rightarrow b \rightarrow b
$$

--
* It's called Skolemization.

--
* The technique is to convert the annotated type expression into prenex form and see if one is more generalized than the other.

---

## Skolemization

* Recursivelly floating out the `Forall`

``` haskell
skolemise :: Sigma -> Tc ([TyVar], Rho)
-- Performs deep skolemisation, retuning the•
-- skolem constants and the skolemised type
skolemise (ForAll tvs ty)›  -- Rule PRPOLY
  = do { sks1 <- mapM newSkolemTyVar tvs
       ; (sks2, ty') <- skolemise (substTy tvs (map TyVar sks1) ty)
       ; return (sks1 ++ sks2, ty') }
skolemise (Fun arg_ty res_ty)›  -- Rule PRFUN
  = do { (sks, res_ty') <- skolemise res_ty
       ; return (sks, Fun arg_ty res_ty') }
skolemise ty ›  ›   ›   -- Rule PRMONO
  = return ([], ty)
```

---

## Subsumption

* How do we tell if one of the polytype could subsume another?
* Replace one of the polytype with type variable (It's called skolemize), and see if the other polytype could instantiate it.
* It checks if `sigma2` is at least as polymorphic as `sigma1 -> exp`

``` haskell
subsCheck :: Sigma -> Sigma -> Tc ()
subsCheck sigma1 sigma2        -- Rule DEEP-SKOL
  = do { (skol_tvs, rho2) <- skolemise sigma2
       ; subsCheckRho sigma1 rho2
       ; esc_tvs <- getFreeTyVars [sigma1,sigma2]
       ; let bad_tvs = filter (`elem` esc_tvs) skol_tvs
       ; check (null bad_tvs)
               (vcat [text "Subsumption check failed:",
                      nest 2 (ppr sigma1),
                      text "is not as polymorphic as",
                      nest 2 (ppr sigma2)])
```

---

## Subsumption

* `rho2` is in prenex form

``` haskell
subsCheckRho :: Sigma -> Rho -> Tc ()
subsCheckRho sigma1@(ForAll _ _) rho2›   -- Rule SPEC
  = do { rho1 <- instantiate sigma1
       ; subsCheckRho rho1 rho2 }
subsCheckRho rho1 (Fun a2 r2)            -- Rule FUN
  = do { (a1,r1) <- unifyFun rho1; subsCheckFun a1 r1 a2 r2 }
subsCheckRho (Fun a1 r1) rho2            -- Rule FUN
  = do { (a2,r2) <- unifyFun rho2; subsCheckFun a1 r1 a2 r2 }
subsCheckRho tau1 tau2                   -- Rule MONO
  = unify tau1 tau2    -- Revert to ordinary unification

subsCheckFun :: Sigma -> Rho -> Sigma -> Rho -> Tc ()
subsCheckFun a1 r1 a2 r2 = do { subsCheck a2 a1; subsCheckRho r1 r2 }
```

---

## Wrapping up

* The hindley milner system is the foundation of Haskell98 standrad. With the knowledge about it, we could understand its extensions and new models inspired by HM.
* Higher rank corresponds to GHC's extension -XRankNTypes, with this addon, we could make the use case like passing in callback function to be typeable.
* This slide tries to avoid any mathematical logical deduction for better comprehension. But to understand other papers, you still have to pickup the intuition of mathematical logic.

---

class: center, middle, large

Thank you


    </textarea>
    <script>
        var is_local = (window.location.hostname == "localhost");

        function add_script(src, callback) {
            var s = document.createElement("script");
            s.setAttribute("src", src);
            s.onload = callback;
            document.body.appendChild(s);
        }

        function load_slides() {
            var query = window.location.search.substring(1);
            var slideshow = remark.create();

            // Setup MathJax
            MathJax.Hub.Config({
                tex2jax: {
                    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
                    inlineMath: [ ['$','$'], ["\\(","\\)"] ],
                    processescapes: true,
                },
                jax: ["input/TeX","output/HTML-CSS"],
                displayAlign: "left",
                displayIndent: "2em"
            });


            MathJax.Hub.Configured();
        }

        if (is_local) {
            add_script("javascript/remark-latest.min.js", function() {
                add_script("javascript/MathJax.js", load_slides);
            });
        } else {
            add_script("https://gnab.github.io/remark/downloads/remark-latest.min.js", function() {
                add_script("http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML&delayStartupUntil=configured", load_slides);
            });
        }
    </script>
  </body>
</html>
